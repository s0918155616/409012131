{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jieba 結巴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們先來安裝結巴："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/19.2 MB 222.6 kB/s eta 0:01:27\n",
      "     --------------------------------------- 0.0/19.2 MB 393.8 kB/s eta 0:00:49\n",
      "     --------------------------------------- 0.1/19.2 MB 573.4 kB/s eta 0:00:34\n",
      "     --------------------------------------- 0.2/19.2 MB 898.2 kB/s eta 0:00:22\n",
      "     --------------------------------------- 0.2/19.2 MB 986.4 kB/s eta 0:00:20\n",
      "      --------------------------------------- 0.4/19.2 MB 1.5 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.5/19.2 MB 1.7 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.6/19.2 MB 1.9 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.8/19.2 MB 2.0 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 1.2/19.2 MB 2.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 1.2/19.2 MB 2.7 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 1.2/19.2 MB 2.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 2.1/19.2 MB 3.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.2/19.2 MB 3.7 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 3.0/19.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 3.2/19.2 MB 4.6 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 3.4/19.2 MB 4.6 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 3.7/19.2 MB 4.7 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.9/19.2 MB 4.7 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.1/19.2 MB 4.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.4/19.2 MB 4.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.7/19.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 4.9/19.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 5.2/19.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 5.4/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 5.6/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 5.8/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 6.0/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 6.2/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 6.5/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 6.6/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 6.8/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 7.0/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.2/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.4/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.7/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 7.9/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 8.1/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 8.3/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 8.5/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 8.7/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 8.9/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 9.1/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.2/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.2/19.2 MB 5.0 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.3/19.2 MB 4.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 9.8/19.2 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 10.0/19.2 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.2/19.2 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.3/19.2 MB 5.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.5/19.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 10.6/19.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 10.8/19.2 MB 5.3 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 11.0/19.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 11.2/19.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 11.3/19.2 MB 5.3 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 11.5/19.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 11.6/19.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 11.8/19.2 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 12.0/19.2 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 12.2/19.2 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 12.4/19.2 MB 5.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 12.6/19.2 MB 5.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 12.8/19.2 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 12.9/19.2 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.1/19.2 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.2/19.2 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.3/19.2 MB 4.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.4/19.2 MB 4.7 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.4/19.2 MB 4.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 13.8/19.2 MB 4.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 13.9/19.2 MB 4.6 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.0/19.2 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.1/19.2 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.3/19.2 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.4/19.2 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 14.6/19.2 MB 4.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 14.7/19.2 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 14.8/19.2 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 14.9/19.2 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 15.1/19.2 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 15.2/19.2 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 15.4/19.2 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 15.5/19.2 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 15.6/19.2 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 15.8/19.2 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 16.0/19.2 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 16.1/19.2 MB 4.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 16.2/19.2 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.3/19.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.4/19.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.4/19.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.6/19.2 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 16.7/19.2 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 16.9/19.2 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 17.0/19.2 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 17.1/19.2 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 17.2/19.2 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.3/19.2 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.4/19.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.5/19.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.6/19.2 MB 3.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.6/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 17.7/19.2 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 17.8/19.2 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 17.9/19.2 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.0/19.2 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.0/19.2 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.1/19.2 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.1/19.2 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.2/19.2 MB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.3/19.2 MB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.4/19.2 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.5/19.2 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.6/19.2 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.6/19.2 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 18.7/19.2 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  18.8/19.2 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  18.9/19.2 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.0/19.2 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.0/19.2 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.1/19.2 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  19.2/19.2 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 19.2/19.2 MB 2.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314474 sha256=28d4668980813988779657a5f3fd5be1a19fd774acae92be8df673f7272d3bb1\n",
      "  Stored in directory: c:\\users\\uer\\appdata\\local\\pip\\cache\\wheels\\ac\\60\\cf\\538a1f183409caf1fc136b5d2c2dee329001ef6da2c5084bef\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安裝好Jieba之後，要使用Jieba就和一般的Python套件一樣，需要先import載入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Jieba 分詞\n",
    "\n",
    "要利用Jieba進行分詞，我們只要呼叫它的`cut()`函式就行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = jieba.cut(\"我愛自然語言處理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cut()`函式會傳回一個清單的generator，我們可以把它轉成清單印出來看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '愛', '自然', '語言', '處理']\n"
     ]
    }
   ],
   "source": [
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你會發現Jieba把「自然語言處理」斷成「自然」「語言」「處理」了，因為它不知道有「自然語言處理」這個詞。\n",
    "\n",
    "在Jieba之中，我們可以呼叫 `add_word()` 函式，自己新增詞條到字典裡面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.add_word(\"自然語言處理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這時候我們再來斷同樣一句試試看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '愛', '自然語言處理']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"我愛自然語言處理\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，自然語言處理已經被斷成一個詞了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Jieba分詞模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們剛剛已經學會使用Jieba提供的`cut()`函式來進行分詞了，不過在Jieba的分詞其實有三種模式：\n",
    "1. 精確模式\n",
    " * 將句子裡面的詞以最精確的方式分開，結巴會找出最佳的斷法，預設是這個模式，適合文本分析使用\n",
    "2. 全模式\n",
    " * 結巴會把所有可能找到的詞都吐出來\n",
    "3. 搜尋引擎模式\n",
    " * 結巴會把比較長的詞也再進一步斷開，適合作為產生搜尋引擎的查詢關鍵字使用。\n",
    " \n",
    " 我們實際上來試試看這三種模式，首先是我們已經會用的精確模式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['國立', '臺', '灣', '博物', '館', '的', '前身', '是', '臺', '灣總', '督府', '博物', '館']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"國立臺灣博物館的前身是臺灣總督府博物館\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你會發現這次結巴的分詞結果感覺很差，它連「臺灣」和「博物館」這麼基本的詞都認不出來。這是因為結巴內建的詞庫是以簡體中文為主的，對於繁體中文的處理並不是很好。如果我們希望結巴能對於繁體中文的分詞能做得好一點，我們可以指定Jieba要使用的詞庫。\n",
    "\n",
    "結巴官網提供了一個叫作 `dict.txt.big` 的詞庫檔案，包含了完整的簡體與繁體中文詞庫，我們下載下來後，可以用Jieba提供的`set_dictionary()`函式來設定詞庫："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "jieba: file does not exist: C:\\Users\\uer\\Downloads\\dict.txt.big",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jieba\u001b[38;5;241m.\u001b[39mset_dictionary(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict.txt.big\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda311\\Lib\\site-packages\\jieba\\__init__.py:513\u001b[0m, in \u001b[0;36mTokenizer.set_dictionary\u001b[1;34m(self, dictionary_path)\u001b[0m\n\u001b[0;32m    511\u001b[0m abs_path \u001b[38;5;241m=\u001b[39m _get_abs_path(dictionary_path)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(abs_path):\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjieba: file does not exist: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m abs_path)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary \u001b[38;5;241m=\u001b[39m abs_path\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: jieba: file does not exist: C:\\Users\\uer\\Downloads\\dict.txt.big"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary('dict.txt.big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，這時候我們再來試一下剛剛的句子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['國立', '臺', '灣', '博物', '館', '的', '前身', '是', '臺', '灣總', '督府', '博物', '館']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"國立臺灣博物館的前身是臺灣總督府博物館\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，這次分詞的結果是不是好多了！\n",
    "\n",
    "接下來我們來試試看「全模式」，要使用全模式，只要在`cut()`函式裡面加上`cut_all=True`的參數就行，就像這樣："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['國', '立', '臺', '灣', '博物', '館', '的', '前身', '是', '臺', '灣', '總', '督府', '博物', '館']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"國立臺灣博物館的前身是臺灣總督府博物館\", cut_all=True)\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你會發現結巴對於「博物館」這個詞吐出了「博物」和「博物館」，「總督府」這個詞吐出了「總督」「總督府」和「督府」。這是因為這些都是結巴在它的分詞演算法處理的過程之中發現的所有可能之組合，使用全模式就會把它們全部都列出來，而精確模式時，結巴會選擇「博物館」與「總督府」的組合作為最佳的答案。\n",
    "\n",
    "接下來我們來看一下最後一種模式「搜尋引擎模式」，要使用這個模式，我們不能再用原本的`cut()`函式，我們要換成`cut_for_search()`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['國立', '臺', '灣', '博物', '館', '的', '前身', '是', '臺', '灣總', '督府', '博物', '館']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut_for_search(\"國立臺灣博物館的前身是臺灣總督府博物館\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個...搜尋引擎模式和全模式看起來沒有什麼不同嘛！好吧，這是因為這句話沒什麼差別，我們換一句來試試看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精確模式: ['小明', '碩士', '畢業', '於', '國立', '臺', '灣大學', '，', '後', '在', '日本', '京都', '大學', '深造']\n",
      "全模式: ['小', '明', '碩', '士', '畢', '業', '於', '國', '立', '臺', '灣', '大', '學', '，', '後', '在', '日本', '京都', '大', '學', '深造']\n",
      "搜尋引擎模式: ['小明', '碩士', '畢業', '於', '國立', '臺', '灣大學', '，', '後', '在', '日本', '京都', '大學', '深造']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"小明碩士畢業於國立臺灣大學，後在日本京都大學深造\")\n",
    "print(\"精確模式: {0}\".format(list(seg_list)))\n",
    "seg_list = jieba.cut(\"小明碩士畢業於國立臺灣大學，後在日本京都大學深造\", cut_all=True)\n",
    "print(\"全模式: {0}\".format(list(seg_list)))\n",
    "seg_list = jieba.cut_for_search(\"小明碩士畢業於國立臺灣大學，後在日本京都大學深造\")\n",
    "print(\"搜尋引擎模式: {0}\".format(list(seg_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Jieba使用者自定詞典\n",
    "\n",
    "在前面我們學到Jieba提供了`add_word()`函式可以動態把我們想要的詞加入詞典，其實它也提供了`del_word()`的函式，可以動態地把某一個詞從詞典裡刪除。但是這些增刪都只在當下有效，Python關閉之後就什麼也都不記得了。而且，如果我們想要加入的詞很多，一個一個加進去了太累了。\n",
    "\n",
    "其實，就像`set_dictionary()`函式用來切換載入詞典檔一樣，Jieba也提供了一個叫作`load_userdict()`的函式，可以額外載入我們自定的詞典。本次上課我們提供了一個自定詞典的範例檔案 `userdict.txt`，就是結巴可用的自定詞典。\n",
    "\n",
    "自定詞典的檔案格式很簡單，是一個用UTF-8編碼的文字檔，每一行就是一個詞，而每一個有三個欄位，每個欄位用空白隔開：\n",
    "1. 詞\n",
    "2. 詞頻 (可省略)\n",
    "3. 詞性 (可省略)\n",
    "\n",
    "像是這樣：\n",
    "```\n",
    "法鼓文理學院 5 nt\n",
    "自然語言處理 30 nl\n",
    "德仁 10 nr\n",
    "即位禮正殿之儀\n",
    "```\n",
    "\n",
    "詞頻和詞性若不知道可以省略，不要亂打，不然會影響Jieba演算法的正確率。詞性的標注方法是依據中國的[ictclas兼容的表記法](https://gist.github.com/luw2007/6016931)。\n",
    "\n",
    "我們先來看看在還沒載入我們的自定詞典之前，結巴對於下面兩句話的分詞結果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['法鼓', '文理', '學院', '舉辦', '演講', '活動']\n",
      "['日本', '德', '仁天皇', '「', '即位', '禮', '正殿', '之儀', '」', '！', '各國', '皇室', '成員', '出席']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"法鼓文理學院舉辦演講活動\")\n",
    "print(list(seg_list))\n",
    "seg_list = jieba.cut(\"日本德仁天皇「即位禮正殿之儀」！各國皇室成員出席\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們發現「法鼓文理學院」被斷成兩個詞，而日本今上天皇的名字「德仁」也被斷錯了，此外結巴也不認得「即位禮正殿之儀」這個詞。\n",
    "\n",
    "我們接下來載入我們自定義的詞典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'userdict.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jieba\u001b[38;5;241m.\u001b[39mload_userdict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserdict.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda311\\Lib\\site-packages\\jieba\\__init__.py:398\u001b[0m, in \u001b[0;36mTokenizer.load_userdict\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, string_types):\n\u001b[0;32m    397\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 398\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    400\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m resolve_filename(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'userdict.txt'"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入完之後，我們再來斷同樣的兩句話："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['法鼓', '文理', '學院', '舉辦', '演講', '活動']\n",
      "['日本', '德', '仁天皇', '「', '即位', '禮', '正殿', '之儀', '」', '！', '各國', '皇室', '成員', '出席']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"法鼓文理學院舉辦演講活動\")\n",
    "print(list(seg_list))\n",
    "seg_list = jieba.cut(\"日本德仁天皇「即位禮正殿之儀」！各國皇室成員出席\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「法鼓文理學院」及「即位禮正殿之儀」被正確地斷出來了！但是天皇的名字仍然怪怪的，這是因為原本的內建詞庫裡面有一個「仁天皇」的詞，所以結巴還是選擇斷成「德/仁天皇」\n",
    "\n",
    "如果我們希望結巴能正確地處理天皇的名字，我們可以建議結巴把「仁天皇」這個詞分開，這時就要用到`suggest_freq()`函式了，就像這樣："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('仁', '天皇'), tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['日本', '德仁', '天皇', '「', '即位', '禮', '正殿', '之儀', '」', '！', '各國', '皇室', '成員', '出席']\n"
     ]
    }
   ],
   "source": [
    "seg_list = jieba.cut(\"日本德仁天皇「即位禮正殿之儀」！各國皇室成員出席\")\n",
    "print(list(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Jieba 詞性標注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前的Jieba套件也有提供詞性標注的功能，除了分詞之外也會一併提供詞性。要利用結巴的詞性標注，我們要先載入相應的套件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要進行詞性標注，我們呼叫的是 `jieba.posseg` 提供的 `cut()` 函式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pseg.cut(\"我每天都要吃義大利麵\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cut()` 函式傳回來的是一個由詞與詞性所構成的 tuple 的清單 generator，我們利用迴圈印出來試試看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "每天 r\n",
      "都 d\n",
      "要 v\n",
      "吃 v\n",
      "義 ng\n",
      "大利 n\n",
      "麵 zg\n"
     ]
    }
   ],
   "source": [
    "for word, flag in words:\n",
    "    print(\"{0} {1}\".format(word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課堂練習\n",
    "\n",
    "1. 從網路上找一篇中文的新聞，利用Jieba進行斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 請利用本次上課所提供的2024年總統就職演講稿 `speech.txt`，讀入檔案後利用Jieba進行斷詞，統計總統在演講裡面用詞的頻率，並輸出成CSV檔案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'speech.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m     words\u001b[38;5;241m=\u001b[39mjieba\u001b[38;5;241m.\u001b[39mcut(content)\n",
      "File \u001b[1;32m~\\anaconda311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'speech.txt'"
     ]
    }
   ],
   "source": [
    "with open('speech.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    words=jieba.cut(content)\n",
    "\n",
    "    d={}\n",
    "    for w in words:\n",
    "        d[w] +=1\n",
    "    else:\n",
    "        d[w]=1\n",
    "    with open('stat.csv','w',encoding='utf-8')as outf:\n",
    "        outf.write(\"word,frep\\n\")\n",
    "        for w in d:\n",
    "            outf.write(f\"{w},{d[w]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 從CBETA Online裡面找一段經文，利用Jieba進行斷詞，看看會有什麼結果\n",
    "https://cbetaonline.dila.edu.tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
